{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import time\n",
    "import easydict\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tf_pose.estimator import TfPoseEstimator\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "import scripts.label_image as label_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger('TfPoseEstimator-WebCam')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)\n",
    "formatter = logging.Formatter('[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "fps_time = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-19 14:12:17,563] [TfPoseEstimator-WebCam] [DEBUG] initialization mobilenet_thin : C:\\Users\\nakhe\\Desktop\\2021.01.18. human-action-classification\\models\\graph/mobilenet_thin/graph_opt.pb\n",
      "[2021-01-19 14:12:17,566] [TfPoseEstimator] [INFO] loading graph from C:\\Users\\nakhe\\Desktop\\2021.01.18. human-action-classification\\models\\graph/mobilenet_thin/graph_opt.pb(default size=432x368)\n",
      "[2021-01-19 14:12:21,747] [TfPoseEstimator-WebCam] [DEBUG] cam read+\n",
      "[2021-01-19 14:12:21,820] [TfPoseEstimator-WebCam] [INFO] cam image=1280x720\n",
      "[2021-01-19 14:12:21,820] [TfPoseEstimator-WebCam] [DEBUG] +image processing+\n",
      "[2021-01-19 14:12:21,841] [TfPoseEstimator-WebCam] [DEBUG] +postprocessing+\n",
      "[2021-01-19 14:12:22,304] [TfPoseEstimator-WebCam] [DEBUG] +classification+\n",
      "[2021-01-19 14:12:23,845] [TfPoseEstimator-WebCam] [DEBUG] +displaying+\n",
      "[2021-01-19 14:12:23,941] [TfPoseEstimator-WebCam] [DEBUG] +finished+\n",
      "[2021-01-19 14:12:23,941] [TfPoseEstimator-WebCam] [DEBUG] +image processing+\n",
      "[2021-01-19 14:12:23,956] [TfPoseEstimator-WebCam] [DEBUG] +postprocessing+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.450s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-19 14:12:24,750] [TfPoseEstimator-WebCam] [DEBUG] +classification+\n",
      "[2021-01-19 14:12:26,079] [TfPoseEstimator-WebCam] [DEBUG] +displaying+\n",
      "[2021-01-19 14:12:26,098] [TfPoseEstimator-WebCam] [DEBUG] +finished+\n",
      "[2021-01-19 14:12:26,100] [TfPoseEstimator-WebCam] [DEBUG] +image processing+\n",
      "[2021-01-19 14:12:26,109] [TfPoseEstimator-WebCam] [DEBUG] +postprocessing+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.423s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-19 14:12:26,810] [TfPoseEstimator-WebCam] [DEBUG] +classification+\n",
      "[2021-01-19 14:12:28,166] [TfPoseEstimator-WebCam] [DEBUG] +displaying+\n",
      "[2021-01-19 14:12:28,185] [TfPoseEstimator-WebCam] [DEBUG] +finished+\n",
      "[2021-01-19 14:12:28,187] [TfPoseEstimator-WebCam] [DEBUG] +image processing+\n",
      "[2021-01-19 14:12:28,201] [TfPoseEstimator-WebCam] [DEBUG] +postprocessing+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.454s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-19 14:12:28,900] [TfPoseEstimator-WebCam] [DEBUG] +classification+\n",
      "[2021-01-19 14:12:30,216] [TfPoseEstimator-WebCam] [DEBUG] +displaying+\n",
      "[2021-01-19 14:12:30,227] [TfPoseEstimator-WebCam] [DEBUG] +finished+\n",
      "[2021-01-19 14:12:30,228] [TfPoseEstimator-WebCam] [DEBUG] +image processing+\n",
      "[2021-01-19 14:12:30,235] [TfPoseEstimator-WebCam] [DEBUG] +postprocessing+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.411s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-19 14:12:30,965] [TfPoseEstimator-WebCam] [DEBUG] +classification+\n",
      "[2021-01-19 14:12:32,560] [TfPoseEstimator-WebCam] [DEBUG] +displaying+\n",
      "[2021-01-19 14:12:32,565] [TfPoseEstimator-WebCam] [DEBUG] +finished+\n",
      "[2021-01-19 14:12:32,566] [TfPoseEstimator-WebCam] [DEBUG] +image processing+\n",
      "[2021-01-19 14:12:32,571] [TfPoseEstimator-WebCam] [DEBUG] +postprocessing+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.422s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-19 14:12:33,251] [TfPoseEstimator-WebCam] [DEBUG] +classification+\n",
      "[2021-01-19 14:12:34,594] [TfPoseEstimator-WebCam] [DEBUG] +displaying+\n",
      "[2021-01-19 14:12:34,611] [TfPoseEstimator-WebCam] [DEBUG] +finished+\n",
      "[2021-01-19 14:12:34,612] [TfPoseEstimator-WebCam] [DEBUG] +image processing+\n",
      "[2021-01-19 14:12:34,618] [TfPoseEstimator-WebCam] [DEBUG] +postprocessing+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.425s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-19 14:12:35,350] [TfPoseEstimator-WebCam] [DEBUG] +classification+\n",
      "[2021-01-19 14:12:36,789] [TfPoseEstimator-WebCam] [DEBUG] +displaying+\n",
      "[2021-01-19 14:12:36,797] [TfPoseEstimator-WebCam] [DEBUG] +finished+\n",
      "[2021-01-19 14:12:36,798] [TfPoseEstimator-WebCam] [DEBUG] +image processing+\n",
      "[2021-01-19 14:12:36,803] [TfPoseEstimator-WebCam] [DEBUG] +postprocessing+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.422s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-19 14:12:37,488] [TfPoseEstimator-WebCam] [DEBUG] +classification+\n",
      "[2021-01-19 14:12:38,983] [TfPoseEstimator-WebCam] [DEBUG] +displaying+\n",
      "[2021-01-19 14:12:38,991] [TfPoseEstimator-WebCam] [DEBUG] +finished+\n",
      "[2021-01-19 14:12:38,991] [TfPoseEstimator-WebCam] [DEBUG] +image processing+\n",
      "[2021-01-19 14:12:38,997] [TfPoseEstimator-WebCam] [DEBUG] +postprocessing+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.423s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-19 14:12:39,692] [TfPoseEstimator-WebCam] [DEBUG] +classification+\n",
      "[2021-01-19 14:12:41,061] [TfPoseEstimator-WebCam] [DEBUG] +displaying+\n",
      "[2021-01-19 14:12:41,072] [TfPoseEstimator-WebCam] [DEBUG] +finished+\n",
      "[2021-01-19 14:12:41,073] [TfPoseEstimator-WebCam] [DEBUG] +image processing+\n",
      "[2021-01-19 14:12:41,079] [TfPoseEstimator-WebCam] [DEBUG] +postprocessing+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.411s\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-19 14:12:41,791] [TfPoseEstimator-WebCam] [DEBUG] +classification+\n",
      "[2021-01-19 14:12:43,174] [TfPoseEstimator-WebCam] [DEBUG] +displaying+\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Evaluation time (1-image): 0.417s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "args = easydict.EasyDict({\n",
    "    \"camera\": 'video_sample.mp4',\n",
    "    \"resize\": '0x0',\n",
    "    \"resize_out_ratio\": 4.0,\n",
    "    \"model\": 'mobilenet_thin',\n",
    "    \"show_process\": False\n",
    "})\n",
    "\n",
    "logger.debug('initialization %s : %s' % (args.model, get_graph_path(args.model)))\n",
    "w, h = model_wh(args.resize)\n",
    "if w > 0 and h > 0:\n",
    "    e = TfPoseEstimator(get_graph_path(args.model), target_size=(w, h))\n",
    "else:\n",
    "    e = TfPoseEstimator(get_graph_path(args.model), target_size=(432, 368))\n",
    "logger.debug('cam read+')\n",
    "cam = cv2.VideoCapture(args.camera)\n",
    "ret_val, image = cam.read()\n",
    "logger.info('cam image=%dx%d' % (image.shape[1], image.shape[0]))\n",
    "\n",
    "# count = 0\n",
    "while True:\n",
    "\n",
    "    logger.debug('+image processing+')\n",
    "    ret_val, image = cam.read()\n",
    "\n",
    "    logger.debug('+postprocessing+')\n",
    "    humans = e.inference(image, resize_to_default=(w > 0 and h > 0), upsample_size=args.resize_out_ratio)\n",
    "    img = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "\n",
    "    logger.debug('+classification+')\n",
    "    # Getting only the skeletal structure (with white background) of the actual image\n",
    "    image = np.zeros(image.shape,dtype=np.uint8)\n",
    "    image.fill(255) \n",
    "    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "\n",
    "    # Classification\n",
    "    pose_class = label_img.classify(image)\n",
    "\n",
    "    logger.debug('+displaying+')\n",
    "    cv2.putText(img,\n",
    "                \"Current predicted pose is : %s\" %(pose_class),\n",
    "                (10, 10),  cv2.FONT_HERSHEY_SIMPLEX, 0.5,\n",
    "                (0, 255, 0), 2)\n",
    "\n",
    "    cv2.imshow('tf-pose-estimation result', img)\n",
    "\n",
    "    fps_time = time.time()\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "    logger.debug('+finished+')\n",
    "\n",
    "    # For gathering training data \n",
    "    # title = 'img'+str(count)+'.jpeg'\n",
    "    # path = <enter any path you want>\n",
    "    # cv2.imwrite(os.path.join(path , title), image)\n",
    "    # count += 1\n",
    "\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
