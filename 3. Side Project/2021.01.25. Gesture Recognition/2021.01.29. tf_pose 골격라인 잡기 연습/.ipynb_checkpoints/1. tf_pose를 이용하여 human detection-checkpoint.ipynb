{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 모듈 Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import easydict\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tf_pose.networks import get_graph_path, model_wh\n",
    "import os\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 추가 함수 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im_trim(img, x_min, y_min, x_max, y_max): #함수로 만든다\n",
    "    img_trim = img[int(y_min):int(y_max), int(x_min):int(x_max)] #trim한 결과를 img_trim에 담는다\n",
    "    return img_trim #필요에 따라 결과물을 리턴"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# estimator.py 오버로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import math\n",
    "import slidingwindow as sw\n",
    "import cv2\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import time\n",
    "from tf_pose import common\n",
    "from tf_pose.common import CocoPart\n",
    "from tf_pose.tensblur.smoother import Smoother\n",
    "\n",
    "try:\n",
    "    from tf_pose.pafprocess import pafprocess\n",
    "except ModuleNotFoundError as e:\n",
    "    print(e)\n",
    "    print('you need to build c++ library for pafprocess. See : https://github.com/ildoonet/tf-pose-estimation/tree/master/tf_pose/pafprocess')\n",
    "    exit(-1)\n",
    "\n",
    "logger = logging.getLogger('TfPoseEstimator')\n",
    "logger.setLevel(logging.INFO)\n",
    "ch = logging.StreamHandler()\n",
    "formatter = logging.Formatter('[%(asctime)s] [%(name)s] [%(levelname)s] %(message)s')\n",
    "ch.setFormatter(formatter)\n",
    "logger.addHandler(ch)\n",
    "\n",
    "def _round(v):\n",
    "    return int(round(v))\n",
    "\n",
    "def _include_part(part_list, part_idx):\n",
    "    for part in part_list:\n",
    "        if part_idx == part.part_idx:\n",
    "            return True, part\n",
    "    return False, None\n",
    "\n",
    "class Human:\n",
    "    \"\"\"\n",
    "    body_parts: list of BodyPart\n",
    "    \"\"\"\n",
    "    __slots__ = ('body_parts', 'pairs', 'uidx_list', 'score')\n",
    "\n",
    "    def __init__(self, pairs):\n",
    "        self.pairs = []\n",
    "        self.uidx_list = set()\n",
    "        self.body_parts = {}\n",
    "        for pair in pairs:\n",
    "            self.add_pair(pair)\n",
    "        self.score = 0.0\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_uidx(part_idx, idx):\n",
    "        return '%d-%d' % (part_idx, idx)\n",
    "\n",
    "    def add_pair(self, pair):\n",
    "        self.pairs.append(pair)\n",
    "        self.body_parts[pair.part_idx1] = BodyPart(Human._get_uidx(pair.part_idx1, pair.idx1),\n",
    "                                                   pair.part_idx1,\n",
    "                                                   pair.coord1[0], pair.coord1[1], pair.score)\n",
    "        self.body_parts[pair.part_idx2] = BodyPart(Human._get_uidx(pair.part_idx2, pair.idx2),\n",
    "                                                   pair.part_idx2,\n",
    "                                                   pair.coord2[0], pair.coord2[1], pair.score)\n",
    "        self.uidx_list.add(Human._get_uidx(pair.part_idx1, pair.idx1))\n",
    "        self.uidx_list.add(Human._get_uidx(pair.part_idx2, pair.idx2))\n",
    "\n",
    "    def is_connected(self, other):\n",
    "        return len(self.uidx_list & other.uidx_list) > 0\n",
    "\n",
    "    def merge(self, other):\n",
    "        for pair in other.pairs:\n",
    "            self.add_pair(pair)\n",
    "\n",
    "    def part_count(self):\n",
    "        return len(self.body_parts.keys())\n",
    "\n",
    "    def get_max_score(self):\n",
    "        return max([x.score for _, x in self.body_parts.items()])\n",
    "\n",
    "    def get_face_box(self, img_w, img_h, mode=0):\n",
    "        \"\"\"\n",
    "        Get Face box compared to img size (w, h)\n",
    "        :param img_w:\n",
    "        :param img_h:\n",
    "        :param mode:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "        # SEE : https://github.com/ildoonet/tf-pose-estimation/blob/master/tf_pose/common.py#L13\n",
    "        _NOSE = CocoPart.Nose.value\n",
    "        _NECK = CocoPart.Neck.value\n",
    "        _REye = CocoPart.REye.value\n",
    "        _LEye = CocoPart.LEye.value\n",
    "        _REar = CocoPart.REar.value\n",
    "        _LEar = CocoPart.LEar.value\n",
    "\n",
    "        _THRESHOLD_PART_CONFIDENCE = 0.2\n",
    "        parts = [part for idx, part in self.body_parts.items() if part.score > _THRESHOLD_PART_CONFIDENCE]\n",
    "\n",
    "        is_nose, part_nose = _include_part(parts, _NOSE)\n",
    "        if not is_nose:\n",
    "            return None\n",
    "\n",
    "        size = 0\n",
    "        is_neck, part_neck = _include_part(parts, _NECK)\n",
    "        if is_neck:\n",
    "            size = max(size, img_h * (part_neck.y - part_nose.y) * 0.8)\n",
    "\n",
    "        is_reye, part_reye = _include_part(parts, _REye)\n",
    "        is_leye, part_leye = _include_part(parts, _LEye)\n",
    "        if is_reye and is_leye:\n",
    "            size = max(size, img_w * (part_reye.x - part_leye.x) * 2.0)\n",
    "            size = max(size,\n",
    "                       img_w * math.sqrt((part_reye.x - part_leye.x) ** 2 + (part_reye.y - part_leye.y) ** 2) * 2.0)\n",
    "\n",
    "        if mode == 1:\n",
    "            if not is_reye and not is_leye:\n",
    "                return None\n",
    "\n",
    "        is_rear, part_rear = _include_part(parts, _REar)\n",
    "        is_lear, part_lear = _include_part(parts, _LEar)\n",
    "        if is_rear and is_lear:\n",
    "            size = max(size, img_w * (part_rear.x - part_lear.x) * 1.6)\n",
    "\n",
    "        if size <= 0:\n",
    "            return None\n",
    "\n",
    "        if not is_reye and is_leye:\n",
    "            x = part_nose.x * img_w - (size // 3 * 2)\n",
    "        elif is_reye and not is_leye:\n",
    "            x = part_nose.x * img_w - (size // 3)\n",
    "        else:  # is_reye and is_leye:\n",
    "            x = part_nose.x * img_w - size // 2\n",
    "\n",
    "        x2 = x + size\n",
    "        if mode == 0:\n",
    "            y = part_nose.y * img_h - size // 3\n",
    "        else:\n",
    "            y = part_nose.y * img_h - _round(size / 2 * 1.2)\n",
    "        y2 = y + size\n",
    "\n",
    "        # fit into the image frame\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "        x2 = min(img_w - x, x2 - x) + x\n",
    "        y2 = min(img_h - y, y2 - y) + y\n",
    "\n",
    "        if _round(x2 - x) == 0.0 or _round(y2 - y) == 0.0:\n",
    "            return None\n",
    "        if mode == 0:\n",
    "            return {\"x\": _round((x + x2) / 2),\n",
    "                    \"y\": _round((y + y2) / 2),\n",
    "                    \"w\": _round(x2 - x),\n",
    "                    \"h\": _round(y2 - y)}\n",
    "        else:\n",
    "            return {\"x\": _round(x),\n",
    "                    \"y\": _round(y),\n",
    "                    \"w\": _round(x2 - x),\n",
    "                    \"h\": _round(y2 - y)}\n",
    "         \n",
    "    def get_upper_body_box(self, img_w, img_h):\n",
    "        \"\"\"\n",
    "        Get Upper body box compared to img size (w, h)\n",
    "        :param img_w:\n",
    "        :param img_h:\n",
    "        :return:\n",
    "        \"\"\"\n",
    "\n",
    "        if not (img_w > 0 and img_h > 0):\n",
    "            raise Exception(\"img size should be positive\")\n",
    "\n",
    "        _NOSE = CocoPart.Nose.value\n",
    "        _NECK = CocoPart.Neck.value\n",
    "        _RSHOULDER = CocoPart.RShoulder.value\n",
    "        _LSHOULDER = CocoPart.LShoulder.value\n",
    "        _THRESHOLD_PART_CONFIDENCE = 0.3\n",
    "        parts = [part for idx, part in self.body_parts.items() if part.score > _THRESHOLD_PART_CONFIDENCE]\n",
    "        part_coords = [(img_w * part.x, img_h * part.y) for part in parts if\n",
    "                       part.part_idx in [0, 1, 2, 5, 8, 11, 14, 15, 16, 17]]\n",
    "\n",
    "        if len(part_coords) < 5:\n",
    "            return None\n",
    "\n",
    "        # Initial Bounding Box\n",
    "        x = min([part[0] for part in part_coords])\n",
    "        y = min([part[1] for part in part_coords])\n",
    "        x2 = max([part[0] for part in part_coords])\n",
    "        y2 = max([part[1] for part in part_coords])\n",
    "\n",
    "        # # ------ Adjust heuristically +\n",
    "        # if face points are detcted, adjust y value\n",
    "\n",
    "        is_nose, part_nose = _include_part(parts, _NOSE)\n",
    "        is_neck, part_neck = _include_part(parts, _NECK)\n",
    "        torso_height = 0\n",
    "        if is_nose and is_neck:\n",
    "            y -= (part_neck.y * img_h - y) * 0.8\n",
    "            torso_height = max(0, (part_neck.y - part_nose.y) * img_h * 2.5)\n",
    "        #\n",
    "        # # by using shoulder position, adjust width\n",
    "        is_rshoulder, part_rshoulder = _include_part(parts, _RSHOULDER)\n",
    "        is_lshoulder, part_lshoulder = _include_part(parts, _LSHOULDER)\n",
    "        if is_rshoulder and is_lshoulder:\n",
    "            half_w = x2 - x\n",
    "            dx = half_w * 0.15\n",
    "            x -= dx\n",
    "            x2 += dx\n",
    "        elif is_neck:\n",
    "            if is_lshoulder and not is_rshoulder:\n",
    "                half_w = abs(part_lshoulder.x - part_neck.x) * img_w * 1.15\n",
    "                x = min(part_neck.x * img_w - half_w, x)\n",
    "                x2 = max(part_neck.x * img_w + half_w, x2)\n",
    "            elif not is_lshoulder and is_rshoulder:\n",
    "                half_w = abs(part_rshoulder.x - part_neck.x) * img_w * 1.15\n",
    "                x = min(part_neck.x * img_w - half_w, x)\n",
    "                x2 = max(part_neck.x * img_w + half_w, x2)\n",
    "\n",
    "        # ------ Adjust heuristically -\n",
    "\n",
    "        # fit into the image frame\n",
    "        x = max(0, x)\n",
    "        y = max(0, y)\n",
    "        x2 = min(img_w - x, x2 - x) + x\n",
    "        y2 = min(img_h - y, y2 - y) + y\n",
    "        \n",
    "        if _round(x2 - x) == 0.0 or _round(y2 - y) == 0.0:\n",
    "            return None\n",
    "        return {\"x\": _round((x + x2) / 2),\n",
    "                \"y\": _round((y + y2) / 2),\n",
    "                \"w\": _round(x2 - x),\n",
    "                \"h\": _round(y2 - y)}\n",
    "\n",
    "    def __str__(self):\n",
    "        return ' '.join([str(x) for x in self.body_parts.values()])\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class BodyPart:\n",
    "    \"\"\"\n",
    "    part_idx : part index(eg. 0 for nose)\n",
    "    x, y: coordinate of body part\n",
    "    score : confidence score\n",
    "    \"\"\"\n",
    "    __slots__ = ('uidx', 'part_idx', 'x', 'y', 'score')\n",
    "\n",
    "    def __init__(self, uidx, part_idx, x, y, score):\n",
    "        self.uidx = uidx\n",
    "        self.part_idx = part_idx\n",
    "        self.x, self.y = x, y\n",
    "        self.score = score\n",
    "\n",
    "    def get_part_name(self):\n",
    "        return CocoPart(self.part_idx)\n",
    "\n",
    "    def __str__(self):\n",
    "        return 'BodyPart:%d-(%.2f, %.2f) score=%.2f' % (self.part_idx, self.x, self.y, self.score)\n",
    "\n",
    "    def __repr__(self):\n",
    "        return self.__str__()\n",
    "\n",
    "\n",
    "class PoseEstimator:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def estimate_paf(peaks, heat_mat, paf_mat):\n",
    "        pafprocess.process_paf(peaks, heat_mat, paf_mat)\n",
    "\n",
    "        humans = []\n",
    "        for human_id in range(pafprocess.get_num_humans()):\n",
    "            human = Human([])\n",
    "            is_added = False\n",
    "\n",
    "            for part_idx in range(18):\n",
    "                c_idx = int(pafprocess.get_part_cid(human_id, part_idx))\n",
    "                if c_idx < 0:\n",
    "                    continue\n",
    "\n",
    "                is_added = True\n",
    "                human.body_parts[part_idx] = BodyPart(\n",
    "                    '%d-%d' % (human_id, part_idx), part_idx,\n",
    "                    float(pafprocess.get_part_x(c_idx)) / heat_mat.shape[1],\n",
    "                    float(pafprocess.get_part_y(c_idx)) / heat_mat.shape[0],\n",
    "                    pafprocess.get_part_score(c_idx)\n",
    "                )\n",
    "\n",
    "            if is_added:\n",
    "                score = pafprocess.get_score(human_id)\n",
    "                human.score = score\n",
    "                humans.append(human)\n",
    "\n",
    "        return humans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TfPoseEstimator:\n",
    "    # TODO : multi-scale\n",
    "\n",
    "    def __init__(self, graph_path, target_size=(320, 240), tf_config=None):\n",
    "        self.target_size = target_size\n",
    "\n",
    "        # load graph\n",
    "        logger.info('loading graph from %s(default size=%dx%d)' % (graph_path, target_size[0], target_size[1]))\n",
    "        with tf.gfile.GFile(graph_path, 'rb') as f:\n",
    "            graph_def = tf.GraphDef()\n",
    "            graph_def.ParseFromString(f.read())\n",
    "\n",
    "        self.graph = tf.get_default_graph()\n",
    "        tf.import_graph_def(graph_def, name='TfPoseEstimator')\n",
    "        self.persistent_sess = tf.Session(graph=self.graph, config=tf_config)\n",
    "\n",
    "        # for op in self.graph.get_operations():\n",
    "        #     print(op.name)\n",
    "        # for ts in [n.name for n in tf.get_default_graph().as_graph_def().node]:\n",
    "        #     print(ts)\n",
    "\n",
    "        self.tensor_image = self.graph.get_tensor_by_name('TfPoseEstimator/image:0')\n",
    "        self.tensor_output = self.graph.get_tensor_by_name('TfPoseEstimator/Openpose/concat_stage7:0')\n",
    "        self.tensor_heatMat = self.tensor_output[:, :, :, :19]\n",
    "        self.tensor_pafMat = self.tensor_output[:, :, :, 19:]\n",
    "        self.upsample_size = tf.placeholder(dtype=tf.int32, shape=(2,), name='upsample_size')\n",
    "        self.tensor_heatMat_up = tf.image.resize_area(self.tensor_output[:, :, :, :19], self.upsample_size,\n",
    "                                                      align_corners=False, name='upsample_heatmat')\n",
    "        self.tensor_pafMat_up = tf.image.resize_area(self.tensor_output[:, :, :, 19:], self.upsample_size,\n",
    "                                                     align_corners=False, name='upsample_pafmat')\n",
    "        smoother = Smoother({'data': self.tensor_heatMat_up}, 25, 3.0)\n",
    "        gaussian_heatMat = smoother.get_output()\n",
    "\n",
    "        max_pooled_in_tensor = tf.nn.pool(gaussian_heatMat, window_shape=(3, 3), pooling_type='MAX', padding='SAME')\n",
    "        self.tensor_peaks = tf.where(tf.equal(gaussian_heatMat, max_pooled_in_tensor), gaussian_heatMat,\n",
    "                                     tf.zeros_like(gaussian_heatMat))\n",
    "\n",
    "        self.heatMat = self.pafMat = None\n",
    "\n",
    "        # warm-up\n",
    "        self.persistent_sess.run(tf.variables_initializer(\n",
    "            [v for v in tf.global_variables() if\n",
    "             v.name.split(':')[0] in [x.decode('utf-8') for x in\n",
    "                                      self.persistent_sess.run(tf.report_uninitialized_variables())]\n",
    "             ])\n",
    "        )\n",
    "        self.persistent_sess.run(\n",
    "            [self.tensor_peaks, self.tensor_heatMat_up, self.tensor_pafMat_up],\n",
    "            feed_dict={\n",
    "                self.tensor_image: [np.ndarray(shape=(target_size[1], target_size[0], 3), dtype=np.float32)],\n",
    "                self.upsample_size: [target_size[1], target_size[0]]\n",
    "            }\n",
    "        )\n",
    "        self.persistent_sess.run(\n",
    "            [self.tensor_peaks, self.tensor_heatMat_up, self.tensor_pafMat_up],\n",
    "            feed_dict={\n",
    "                self.tensor_image: [np.ndarray(shape=(target_size[1], target_size[0], 3), dtype=np.float32)],\n",
    "                self.upsample_size: [target_size[1] // 2, target_size[0] // 2]\n",
    "            }\n",
    "        )\n",
    "        self.persistent_sess.run(\n",
    "            [self.tensor_peaks, self.tensor_heatMat_up, self.tensor_pafMat_up],\n",
    "            feed_dict={\n",
    "                self.tensor_image: [np.ndarray(shape=(target_size[1], target_size[0], 3), dtype=np.float32)],\n",
    "                self.upsample_size: [target_size[1] // 4, target_size[0] // 4]\n",
    "            }\n",
    "        )\n",
    "\n",
    "    def __del__(self):\n",
    "        # self.persistent_sess.close()\n",
    "        pass\n",
    "\n",
    "    @staticmethod\n",
    "    def _quantize_img(npimg):\n",
    "        npimg_q = npimg + 1.0\n",
    "        npimg_q /= (2.0 / 2 ** 8)\n",
    "        # npimg_q += 0.5\n",
    "        npimg_q = npimg_q.astype(np.uint8)\n",
    "        return npimg_q\n",
    "\n",
    "    # 이 부분 코드 수정하였음.\n",
    "    @staticmethod\n",
    "    def draw_humans(npimg, humans, imgcopy=False):\n",
    "        if imgcopy:\n",
    "            npimg = np.copy(npimg)\n",
    "        image_h, image_w = npimg.shape[:2]\n",
    "        \n",
    "        i = 0\n",
    "        for human in humans:\n",
    "            i = i+1\n",
    "            centers = {}\n",
    "            x_poses = []\n",
    "            y_poses = []\n",
    "            # draw point\n",
    "            for i in range(common.CocoPart.Background.value):\n",
    "                if i not in human.body_parts.keys():\n",
    "                    continue\n",
    "\n",
    "                body_part = human.body_parts[i]\n",
    "                center = (int(body_part.x * image_w + 0.5), int(body_part.y * image_h + 0.5))\n",
    "                centers[i] = center\n",
    "                x_poses.append(center[0])\n",
    "                y_poses.append(center[1])\n",
    "                cv2.circle(npimg, center, 3, common.CocoColors[i], thickness=3, lineType=8, shift=0)\n",
    "\n",
    "            # draw line\n",
    "            for pair_order, pair in enumerate(common.CocoPairsRender):\n",
    "                if pair[0] not in human.body_parts.keys() or pair[1] not in human.body_parts.keys():\n",
    "                    continue\n",
    "\n",
    "                # npimg = cv2.line(npimg, centers[pair[0]], centers[pair[1]], common.CocoColors[pair_order], 3)\n",
    "                cv2.line(npimg, centers[pair[0]], centers[pair[1]], common.CocoColors[pair_order], 3)\n",
    "            \n",
    "            x_min = min(x_poses)\n",
    "            x_max = max(x_poses)\n",
    "            y_min = min(y_poses)\n",
    "            y_max = max(y_poses)\n",
    "            width = x_max - x_min\n",
    "            height = y_max - y_min\n",
    "            \n",
    "            x_min = x_min - (0.3*width)\n",
    "            x_max = x_max + (0.3*width)\n",
    "            y_min = y_min - (0.2*height)\n",
    "            y_max = y_max + (0.2*height)\n",
    "            \n",
    "            trim_img = im_trim(npimg, x_min, y_min, x_max, y_max)\n",
    "            cv2.imwrite('./test_after/{}{}.jpg'.format(x_min, i), trim_img)\n",
    "            \n",
    "        return npimg\n",
    "    \n",
    "    def _get_scaled_img(self, npimg, scale):\n",
    "        get_base_scale = lambda s, w, h: max(self.target_size[0] / float(h), self.target_size[1] / float(w)) * s\n",
    "        img_h, img_w = npimg.shape[:2]\n",
    "\n",
    "        if scale is None:\n",
    "            if npimg.shape[:2] != (self.target_size[1], self.target_size[0]):\n",
    "                # resize\n",
    "                npimg = cv2.resize(npimg, self.target_size, interpolation=cv2.INTER_CUBIC)\n",
    "            return [npimg], [(0.0, 0.0, 1.0, 1.0)]\n",
    "        elif isinstance(scale, float):\n",
    "            # scaling with center crop\n",
    "            base_scale = get_base_scale(scale, img_w, img_h)\n",
    "            npimg = cv2.resize(npimg, dsize=None, fx=base_scale, fy=base_scale, interpolation=cv2.INTER_CUBIC)\n",
    "\n",
    "            o_size_h, o_size_w = npimg.shape[:2]\n",
    "            if npimg.shape[0] < self.target_size[1] or npimg.shape[1] < self.target_size[0]:\n",
    "                newimg = np.zeros(\n",
    "                    (max(self.target_size[1], npimg.shape[0]), max(self.target_size[0], npimg.shape[1]), 3),\n",
    "                    dtype=np.uint8)\n",
    "                newimg[:npimg.shape[0], :npimg.shape[1], :] = npimg\n",
    "                npimg = newimg\n",
    "\n",
    "            windows = sw.generate(npimg, sw.DimOrder.HeightWidthChannel, self.target_size[0], self.target_size[1], 0.2)\n",
    "\n",
    "            rois = []\n",
    "            ratios = []\n",
    "            for window in windows:\n",
    "                indices = window.indices()\n",
    "                roi = npimg[indices]\n",
    "                rois.append(roi)\n",
    "                ratio_x, ratio_y = float(indices[1].start) / o_size_w, float(indices[0].start) / o_size_h\n",
    "                ratio_w, ratio_h = float(indices[1].stop - indices[1].start) / o_size_w, float(\n",
    "                    indices[0].stop - indices[0].start) / o_size_h\n",
    "                ratios.append((ratio_x, ratio_y, ratio_w, ratio_h))\n",
    "\n",
    "            return rois, ratios\n",
    "        elif isinstance(scale, tuple) and len(scale) == 2:\n",
    "            # scaling with sliding window : (scale, step)\n",
    "            base_scale = get_base_scale(scale[0], img_w, img_h)\n",
    "            npimg = cv2.resize(npimg, dsize=None, fx=base_scale, fy=base_scale, interpolation=cv2.INTER_CUBIC)\n",
    "            o_size_h, o_size_w = npimg.shape[:2]\n",
    "            if npimg.shape[0] < self.target_size[1] or npimg.shape[1] < self.target_size[0]:\n",
    "                newimg = np.zeros(\n",
    "                    (max(self.target_size[1], npimg.shape[0]), max(self.target_size[0], npimg.shape[1]), 3),\n",
    "                    dtype=np.uint8)\n",
    "                newimg[:npimg.shape[0], :npimg.shape[1], :] = npimg\n",
    "                npimg = newimg\n",
    "\n",
    "            window_step = scale[1]\n",
    "\n",
    "            windows = sw.generate(npimg, sw.DimOrder.HeightWidthChannel, self.target_size[0], self.target_size[1],\n",
    "                                  window_step)\n",
    "\n",
    "            rois = []\n",
    "            ratios = []\n",
    "            for window in windows:\n",
    "                indices = window.indices()\n",
    "                roi = npimg[indices]\n",
    "                rois.append(roi)\n",
    "                ratio_x, ratio_y = float(indices[1].start) / o_size_w, float(indices[0].start) / o_size_h\n",
    "                ratio_w, ratio_h = float(indices[1].stop - indices[1].start) / o_size_w, float(\n",
    "                    indices[0].stop - indices[0].start) / o_size_h\n",
    "                ratios.append((ratio_x, ratio_y, ratio_w, ratio_h))\n",
    "\n",
    "            return rois, ratios\n",
    "        elif isinstance(scale, tuple) and len(scale) == 3:\n",
    "            # scaling with ROI : (want_x, want_y, scale_ratio)\n",
    "            base_scale = get_base_scale(scale[2], img_w, img_h)\n",
    "            npimg = cv2.resize(npimg, dsize=None, fx=base_scale, fy=base_scale, interpolation=cv2.INTER_CUBIC)\n",
    "            ratio_w = self.target_size[0] / float(npimg.shape[1])\n",
    "            ratio_h = self.target_size[1] / float(npimg.shape[0])\n",
    "\n",
    "            want_x, want_y = scale[:2]\n",
    "            ratio_x = want_x - ratio_w / 2.\n",
    "            ratio_y = want_y - ratio_h / 2.\n",
    "            ratio_x = max(ratio_x, 0.0)\n",
    "            ratio_y = max(ratio_y, 0.0)\n",
    "            if ratio_x + ratio_w > 1.0:\n",
    "                ratio_x = 1. - ratio_w\n",
    "            if ratio_y + ratio_h > 1.0:\n",
    "                ratio_y = 1. - ratio_h\n",
    "\n",
    "            roi = self._crop_roi(npimg, ratio_x, ratio_y)\n",
    "            return [roi], [(ratio_x, ratio_y, ratio_w, ratio_h)]\n",
    "\n",
    "    def _crop_roi(self, npimg, ratio_x, ratio_y):\n",
    "        target_w, target_h = self.target_size\n",
    "        h, w = npimg.shape[:2]\n",
    "        x = max(int(w * ratio_x - .5), 0)\n",
    "        y = max(int(h * ratio_y - .5), 0)\n",
    "        cropped = npimg[y:y + target_h, x:x + target_w]\n",
    "\n",
    "        cropped_h, cropped_w = cropped.shape[:2]\n",
    "        if cropped_w < target_w or cropped_h < target_h:\n",
    "            npblank = np.zeros((self.target_size[1], self.target_size[0], 3), dtype=np.uint8)\n",
    "\n",
    "            copy_x, copy_y = (target_w - cropped_w) // 2, (target_h - cropped_h) // 2\n",
    "            npblank[copy_y:copy_y + cropped_h, copy_x:copy_x + cropped_w] = cropped\n",
    "        else:\n",
    "            return cropped\n",
    "\n",
    "    def inference(self, npimg, resize_to_default=True, upsample_size=1.0):\n",
    "        if npimg is None:\n",
    "            raise Exception('The image is not valid. Please check your image exists.')\n",
    "\n",
    "        if resize_to_default:\n",
    "            upsample_size = [int(self.target_size[1] / 8 * upsample_size), int(self.target_size[0] / 8 * upsample_size)]\n",
    "        else:\n",
    "            upsample_size = [int(npimg.shape[0] / 8 * upsample_size), int(npimg.shape[1] / 8 * upsample_size)]\n",
    "\n",
    "        if self.tensor_image.dtype == tf.quint8:\n",
    "            # quantize input image\n",
    "            npimg = TfPoseEstimator._quantize_img(npimg)\n",
    "            pass\n",
    "\n",
    "        logger.debug('inference+ original shape=%dx%d' % (npimg.shape[1], npimg.shape[0]))\n",
    "        img = npimg\n",
    "        if resize_to_default:\n",
    "            img = self._get_scaled_img(npimg, None)[0][0]\n",
    "        peaks, heatMat_up, pafMat_up = self.persistent_sess.run(\n",
    "            [self.tensor_peaks, self.tensor_heatMat_up, self.tensor_pafMat_up], feed_dict={\n",
    "                self.tensor_image: [img], self.upsample_size: upsample_size\n",
    "            })\n",
    "        peaks = peaks[0]\n",
    "        self.heatMat = heatMat_up[0]\n",
    "        self.pafMat = pafMat_up[0]\n",
    "        logger.debug('inference- heatMat=%dx%d pafMat=%dx%d' % (\n",
    "            self.heatMat.shape[1], self.heatMat.shape[0], self.pafMat.shape[1], self.pafMat.shape[0]))\n",
    "\n",
    "        t = time.time()\n",
    "        humans = PoseEstimator.estimate_paf(peaks, self.heatMat, self.pafMat)\n",
    "        logger.debug('estimate time=%.5f' % (time.time() - t))\n",
    "        return humans"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 데이터셋 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2021-01-29 05:40:26,411] [TfPoseEstimator] [INFO] loading graph from C:\\Users\\nakhe\\Desktop\\UGRP\\2021_UGRP\\personal\\nakon_zoe\\3. Side Project\\2021.01.25. Gesture Recognition\\2021.01.29. tf_pose 골격라인 잡기 연습\\models\\graph/mobilenet_thin/graph_opt.pb(default size=432x368)\n",
      "[2021-01-29 05:40:26,411] [TfPoseEstimator] [INFO] loading graph from C:\\Users\\nakhe\\Desktop\\UGRP\\2021_UGRP\\personal\\nakon_zoe\\3. Side Project\\2021.01.25. Gesture Recognition\\2021.01.29. tf_pose 골격라인 잡기 연습\\models\\graph/mobilenet_thin/graph_opt.pb(default size=432x368)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\nakhe\\Desktop\\UGRP\\2021_UGRP\\personal\\nakon_zoe\\3. Side Project\\2021.01.25. Gesture Recognition\\2021.01.29. tf_pose 골격라인 잡기 연습\\tf_pose\\tensblur\\smoother.py:92: The name tf.variable_scope is deprecated. Please use tf.compat.v1.variable_scope instead.\n",
      "\n",
      "WARNING:tensorflow:From <ipython-input-4-ceb8b8faedef>:36: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# 모델 import\n",
    "e = TfPoseEstimator(get_graph_path('mobilenet_thin'), target_size=(432, 368))\n",
    "\n",
    "# Dataset Path 지정\n",
    "original_path = './test_before/'\n",
    "file_list = os.listdir(original_path) # 해당 path 내의 모든 파일 list 가져오기\n",
    "new_path = './test_after/'\n",
    "\n",
    "for file in file_list:\n",
    "\n",
    "    # input 단위 설정\n",
    "    args = easydict.EasyDict({\"image\": original_path+file})\n",
    "\n",
    "    # image 로드\n",
    "    image = cv2.imread(args.image)\n",
    "\n",
    "    # Skeleton 그리기 with Background\n",
    "    humans = e.inference(image, upsample_size=4.0)\n",
    "    image = TfPoseEstimator.draw_humans(image, humans, imgcopy=False)\n",
    "\n",
    "    # 이미지 저장\n",
    "    cv2.imwrite(new_path+file,image)\n",
    "    \n",
    "    time.sleep(0.1)\n",
    "\n",
    "time.sleep(0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trim_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-979d2496e2df>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtrim_image\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'trim_image' is not defined"
     ]
    }
   ],
   "source": [
    "trim_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(trim_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(trim_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a==None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
